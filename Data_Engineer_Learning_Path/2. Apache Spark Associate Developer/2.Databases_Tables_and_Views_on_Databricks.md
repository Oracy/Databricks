# Learning objectives

1. Describe persistence and scope of databases, tables, and views on Databricks.
2. Compare and contrast the behavior of managed and unmanaged tables.
3. Summarize best practices for creating and managing databases, tables, and views on Databricks.

---

1. R:
    - Explain how the LOCATION keyword changes the default location of database contents.
    - Compare and contrast the behavior of managed and unmanaged tables.

---

## Metastore basics

- Default Hive metastore managed by Databricks, but can bring your own.
- Stores information (metadata) necessary to query database entities
  - Schemas
  - Locations
- Persistent to the life of the workspace

## Spark catalog

- Provides the interface to manage the metastore
- Stores temporary entities
- Each SparkSession initializes a Spark catalog
- A new SparkSession is created when a notebook is attached to a cluster
- The notebook's SparkSession is deleted when the notebook is detached from a cluster

## Clusters

- Interactive clusters are available to all workspace users with correct permissions
- Job clusters are ephemeral and isolated to a specific job

## Databases

- Databases are logical constructs that organize tables
- Think of them as creating a "namespace" for a set of tables
- Simplifies discovery and management of data stored in diverse locations
- Created against a physical location on an object store
  - Becomes the directory in which managed tables are created
  - Default directory is determined by Spark config `spark.sql.warehouse.dir`
  - Default Databricks location is `dbfs/user/hive/warehouse/`
  - Use LOCATINO to change the default location of managed tables
- Examples
  - `CREATE DATABASE database1;`
    - Uses default location for managed tables
  - `CREATE DATABASE database2 LOCATION <path-to-location>;`
    - Uses custom location for managed tables
    - `path-to-location` could be dbfs which is not recommended and object store on cloud platform, which is recommended.
- Other options available for CREATE DATABASE in the documentation

## Tables

- Directory of files registered as a relation in a database
- Data location, file type, and schema registered in the metastore
- Underlying files can be of any type
  - Default = Delta
- Table data persists in the object store
- An active cluster is required to query the metastore and object store

## Managed tables

- Default behavior of create/save table operations
- Data is writtern to a new directory in the database directory
  - Data will always be written when creating a non-empty managed table
  - Default location: `dbfs/user/hive/warehouse/<database_name>.db/<new_table_name>/`
- Data lifecycle managed by the metastore:
  - Drop table operation permanently deletes data
  - Changing relational structure of tables/databases requires pysically moving data

## External tables

- In Databricks, synonymous with unmanaged tabels
- Created in two ways
  - Specifying the location to save data when creating a new table
    - Example: `CREATE TABLE table1 LOCATION <path-to-new-location>...;`
  - Providing the location of existing data when registering a table
- Data lifecycle not tied to metastore operations:
  - Drop table operation removes metadata from metastore, but data is not dropped
  - Can easily clone a table to a new database or table name without moving data

## Location of table data

|Table Type|Default Location|LOCATION declared|
|:---:|:---:|:---:|
|Managed|`spark.sql.warehouse.dir` <br> Default=`dbfs/user/hive/warehouse<database_name>.db`|Based on LOCATION specified when database was created|
|External|LOCATION specified in CREATE TABLE query|LOCATION specified in CREATE TABLE query|

## Effect of Dropping Tables

|Table Type|LOCATION not used|LOCATION used|
|:---:|:---:|:---:|
|Managed|Data Deleted|Data Deleted|
|External|Data Persist|Data Persist|

## Summary

- Metadata for Databases and tables are persisted in the Hive Metastore
- Using LOCATION in CREATE DATABASE provides a custom location for managed tables
- Managed tables copy data on CREATE and delete data on DROP
- Unmanaged tables use LOCATION in CREATE
- Unmanaged table data remain in the LOCATION specified even when the table is DROPped.

---

## Views and CTEs on Databricks

1. Discuss differences between views, temp, views, and global temp views
2. Discuss CTEs and talk about limited persistence
3. Summarize best practices for creating and managing databases, tables, and views on Databricks (without being prescriptive)

### Views

- Views register logical queries using the physical plan generated by Catalyst
- Recalculate results each time a view is materialized
- Three different types:
  - Views
  - Temp Views
  - Global Temp Views
- Persists in the metastore
- Available across workspace and between sessions
- Example:

```sql
create view view_table as select * from table;
```

### Global Temp Views

- Do not persist to the metastore
- Available to any notebook attached to the cluster
- Persists until the cluster is terminated
- Registered in the global_temp database
- Must be prefixed with global_temp
- Example

```sql
create global temporary view view_table as select * from table;
select * from global_temp.table;
```

### Common Table Expressions (CTEs)

- Scoped only to the current SQL statement

### Suggestions for Best Practices

- Use Delta as the data format when creating tables
- If possible, use external tables
- If not, try to use a location when creating databases
- Locations outside of dbfs provide the most flexibility

### SUmmary

- Views run each time they are referenced in a query
- Views persist to the metastore for the life of the workspace
- Temporary Views only persist while the notebook is attached to a cluster
- Global Temporary Views persist to the cluster and are available to any notebook attached to the cluster until the cluster is terminated
- CTEs persist only for the current SQL statement
